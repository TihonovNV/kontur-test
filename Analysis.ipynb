{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CONSONANTS = 'бвгджзйклмнпрстфхцчшщБВГДЖЗЙКЛМНПРСТФХЦЧШЩbcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXZ'\n",
    "VOWELS = 'аиоуэыеёюяАИОУЭЫЕЁЮЯaeiouyAEIOUY'\n",
    "ALPHABET = 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюяaeiouyAEIOUYbcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_companies = open('../kontur_srs_internship_test_task/train.txt', 'r').readlines()\n",
    "train_companies = list(map(lambda s: s.strip(), train_companies))\n",
    "\n",
    "test_companies = open('../kontur_srs_internship_test_task/test.txt', 'r').readlines()\n",
    "test_companies = list(map(lambda s: s.strip(), test_companies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем самое длинное слово (для нормализации), плюс добавим пару функций для генерации фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(company, spaces=False):\n",
    "    with_spaces = list(filter(None, re.split('(\\w+| )', company)))\n",
    "    if(spaces):\n",
    "        return with_spaces\n",
    "    return [token for token in with_spaces if token != ' ']\n",
    "\n",
    "\n",
    "def has_letters(string):\n",
    "    return any(char in ALPHABET for char in string)\n",
    "\n",
    "def has_not_letters(string):\n",
    "    return any(char not in ALPHABET for char in string)\n",
    "\n",
    "def count_vowels(string):\n",
    "    return len([char for char in string if char in VOWELS])\n",
    "\n",
    "def count_consonants(string):\n",
    "    return len([char for char in string if char in CONSONANTS])\n",
    "\n",
    "def find_max_str(companies):\n",
    "    max_str = ''\n",
    "    for company in companies:\n",
    "        for word in tokenize(company):\n",
    "            if(has_letters(word)):\n",
    "                max_str = word if len(max_str) < len(word) else max_str \n",
    "    return max_str\n",
    "\n",
    "def find_index_of_substring(string, companies):\n",
    "    for i in range(len(companies)):\n",
    "        if(companies[i].find(string) != -1):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'МОСКОВСКАЯИНВЕСТИЦИОННАЯЭКСПЛУТАЦИОННАЯКОМПАНИЯ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_max_str = find_max_str(test_companies)\n",
    "test_max_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ОБЩЕСТВО С ОГРАНИЧЕННОЙ ОТВЕТСТВЕННОСТЬЮ \"МОСКОВСКАЯИНВЕСТИЦИОННАЯЭКСПЛУТАЦИОННАЯКОМПАНИЯ\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_max_str_index = find_index_of_substring(test_max_str, test_companies)\n",
    "test_companies[test_max_str_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смешное название, однако"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'КотельниковскаOРрайоннаOРорганизациOРВолгоградско9Робластно9Рорганизаци8Робщероссийско9Робщественно9Рорганизаци8'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_str = find_max_str(train_companies)\n",
    "train_max_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'КотельниковскаOРрайоннаOРорганизациOРВолгоградско9Робластно9Рорганизаци8Робщероссийско9Робщественно9Рорганизаци8 \"Всероссийское общество инвалидов\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_str_index = find_index_of_substring(train_max_str, train_companies)\n",
    "train_companies[train_max_str_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_companies[train_max_str_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'КонсультацииОбразованиеНовыеТехнологииУправленияРесурсами'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_str = find_max_str(train_companies)\n",
    "train_max_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Автономная Некоммерческая Организация \"КонсультацииОбразованиеНовыеТехнологииУправленияРесурсами\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_str_index = find_index_of_substring(train_max_str, train_companies)\n",
    "train_companies[train_max_str_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_max_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно пригодилось бы для нормализации букв по частоте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "from collections import Counter\n",
    "\n",
    "with open('kontur_srs_internship_test_task/train.txt') as f:\n",
    "    print(Counter(letter for line in f \n",
    "                  for letter in line.lower() \n",
    "                  if letter in ALPHABET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'О': 35312904, ' ': 25422815, 'Н': 24537989, 'Е': 23969940, 'Т': 21420192, 'С': 19892386, 'А': 16809787, 'И': 14950389, 'Р': 13874547, 'В': 13280775, '\"': 9695019, 'К': 7858626, 'Г': 5914467, 'Л': 5851872, 'Б': 5428314, 'Й': 5352151, '\\n': 5232476, 'Ь': 4866345, 'П': 4642709, 'Д': 4606840, 'М': 4369257, 'Ч': 3898716, 'Я': 3613597, 'У': 3592997, 'Щ': 3302510, 'Ю': 3018424, 'З': 2625035, 'Ц': 2040518, 'Ы': 1500303, '-': 1443125, 'Ж': 1273203, 'Ф': 1136416, 'Х': 1122008, 'Ш': 674331, 'Э': 502713, '.': 406987, '№': 214440, '1': 194707, '2': 167236, '(': 124233, ')': 124117, '0': 102588, ',': 95619, '3': 92674, '4': 73813, '5': 68067, '7': 58772, '9': 58326, '6': 56049, 'Ъ': 55448, '8': 47595, 'Ё': 29626, 'I': 29581, '/': 28983, '+': 25175, 'X': 13675, \"'\": 12332, '`': 8071, 'N': 7230, 'T': 5980, 'V': 5571, 'O': 5074, 'A': 5020, 'E': 4842, 'R': 4648, 'L': 4577, 'S': 4524, 'C': 4156, 'P': 3837, 'D': 3460, 'M': 2589, ':': 1590, '!': 1578, '&': 1530, 'U': 1491, 'G': 1320, '<': 1152, 'H': 1102, '>': 1069, 'F': 1058, 'Y': 1054, 'B': 1005, 'K': 927, ';': 892, '\\\\': 634, 'W': 541, '°': 509, '«': 427, 'Z': 379, '»': 378, '*': 374, '%': 237, '_': 237, 'J': 226, '?': 120, 'Q': 58, '=': 48, '@': 45, '–': 41, '^': 29, '{': 24, '}': 23, '[': 16, '~': 16, ']': 14, '$': 12, '#': 12, '‹': 10, '›': 10, '·': 8, '|': 7, '“': 6, '”': 6, '©': 3, '—': 2, '§': 2, '’': 2, '™': 2, '®': 1, 'Є': 1, '\\xa0': 1, '±': 1, '…': 1, '¶': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "my_str = open('../kontur_srs_internship_test_task/train.txt', 'r').read().upper()\n",
    "counter = Counter(my_str)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_words = []\n",
    "for company in train_companies[:-1000000]:\n",
    "    for word in tokenize(company):\n",
    "        if not word[1:].islower() and not word[1:].isupper() and len(word) > 5:\n",
    "            mixed_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'w') as input_file:\n",
    "    for mixed_word in mixed_words:\n",
    "        input_file.write(mixed_word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_words_test = []\n",
    "for company in train_companies[-1000000:]:\n",
    "    for word in tokenize(company):\n",
    "        if not word[1:].islower() and not word[1:].isupper() and len(word) > 5:\n",
    "            mixed_words_test.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lower = open('test.lower.txt', 'w')\n",
    "test = open('test.txt', 'w')\n",
    "for mixed_word in mixed_words_test:\n",
    "    test_lower.write(mixed_word.lower() + '\\n')\n",
    "    test.write(mixed_word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['АлтайПак',\n",
       " 'РусАвтоПром',\n",
       " 'АлтайТрансСервис',\n",
       " 'АлтайСиб',\n",
       " 'ВалСтрой',\n",
       " 'ИнфоГарант',\n",
       " 'ИнжРемСервис',\n",
       " 'ГрандМаркет',\n",
       " 'ЗапСибМост',\n",
       " 'СибТЭК']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_words[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_max_str(mixed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter({'О': 35312904, ' ': 25422815, 'Н': 24537989, 'Е': 23969940, 'Т': 21420192, 'С': 19892386, 'А': 16809787, 'И': 14950389, 'Р': 13874547, 'В': 13280775, '\"': 9695019, 'К': 7858626, 'Г': 5914467, 'Л': 5851872, 'Б': 5428314, 'Й': 5352151, '\\n': 5232476, 'Ь': 4866345, 'П': 4642709, 'Д': 4606840, 'М': 4369257, 'Ч': 3898716, 'Я': 3613597, 'У': 3592997, 'Щ': 3302510, 'Ю': 3018424, 'З': 2625035, 'Ц': 2040518, 'Ы': 1500303, '-': 1443125, 'Ж': 1273203, 'Ф': 1136416, 'Х': 1122008, 'Ш': 674331, 'Э': 502713, '.': 406987, '№': 214440, '1': 194707, '2': 167236, '(': 124233, ')': 124117, '0': 102588, ',': 95619, '3': 92674, '4': 73813, '5': 68067, '7': 58772, '9': 58326, '6': 56049, 'Ъ': 55448, '8': 47595, 'Ё': 29626, 'I': 29581, '/': 28983, '+': 25175, 'X': 13675, \"'\": 12332, '`': 8071, 'N': 7230, 'T': 5980, 'V': 5571, 'O': 5074, 'A': 5020, 'E': 4842, 'R': 4648, 'L': 4577, 'S': 4524, 'C': 4156, 'P': 3837, 'D': 3460, 'M': 2589, ':': 1590, '!': 1578, '&': 1530, 'U': 1491, 'G': 1320, '<': 1152, 'H': 1102, '>': 1069, 'F': 1058, 'Y': 1054, 'B': 1005, 'K': 927, ';': 892, '\\\\': 634, 'W': 541, '°': 509, '«': 427, 'Z': 379, '»': 378, '*': 374, '%': 237, '_': 237, 'J': 226, '?': 120, 'Q': 58, '=': 48, '@': 45, '–': 41, '^': 29, '{': 24, '}': 23, '[': 16, '~': 16, ']': 14, '$': 12, '#': 12, '‹': 10, '›': 10, '·': 8, '|': 7, '“': 6, '”': 6, '©': 3, '—': 2, '§': 2, '’': 2, '™': 2, '®': 1, 'Є': 1, '\\xa0': 1, '±': 1, '…': 1, '¶': 1})\n",
    "print(len(counter))\n",
    "encoding = {}\n",
    "i = 0\n",
    "for char in counter:\n",
    "    encoding[char] = i/len(counter)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((len(mixed_words), MAX_WORD))\n",
    "labels = np.zeros((len(mixed_words), MAX_WORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mixed_words)):\n",
    "    for j in range(len(mixed_words[i])):\n",
    "        features[i][j] = encoding[mixed_words[i][j].upper()]\n",
    "        labels[i][j] = int(mixed_words[i][j].isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26612903, 0.27419355, 0.25      , 0.05645161, 0.05645161,\n",
       "       0.03225806, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7a53a3f2bbdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4302\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   4303\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   1795\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m             \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mallow_clear_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         params['loss_function'] = _get_loss_function_for_train(\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_estimator_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_get_loss_function_for_train\u001b[0;34m(params, estimator_type, train_pool)\u001b[0m\n\u001b[1;32m   1145\u001b[0m              \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbbengfort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2017\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \"\"\"\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mis_multiclass_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'target_border'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'MultiClass'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_multiclass_task\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Logloss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "clf = CatBoostClassifier(iterations=1000, task_type='GPU')\n",
    "clf.fit(list(features), list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219426, 57)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219426, 57)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
